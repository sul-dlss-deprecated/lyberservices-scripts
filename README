==Pre-assembly

This is a Ruby implementation of services needed to prepare objects to be assembled and then accessioned in SULAIR digital library.

==Version History

1.0.0  Released to production
1.2.0  Changed <provider_checksum> node to regular <checksum> node.  Must be run in combination with assembly 1.2.0.
1.2.2  Significant refactoring of cleanup scripts and movement of methods to a new Util class.  Update integration tests.
1.3.0  Add the ability to re-accession
1.3.1  Bug fixes related to re-accessioning
1.3.2  Bug fixes related to smpl content metadata processing
1.3.3  Add the ability to leave the progress log filename as nil in the config file, and it will be created automatically.
1.3.4  Add contentMetadata and resourceTypes of 'image' during pre-assembly if you specify :simple_image as project type.
1.4.6  Add functionality to discovery_report to provide information on whether objects are registered and if they have APOs
1.4.7  Allow "book_as_image" as new project content type.
1.4.8  Fix workflow_status report so it doesn't crash if a workflow is not found
1.4.9  Bug fix in cleanup method
1.5.0  Add the ability to accession or re-accession only specific items via "except" or "only" parameters
1.5.1  Updates to discovery report to only show objects that will be processed
1.5.2  Add some utility methods to quickly update datastreams for a list of DOR objects
1.5.3  Add more options to the discovery_report to make it useful when running manifest style projects
1.5.4  bug fixes to discovery report
1.5.5  Add some more reporting info to the discovery_report (to tell you how many problems were found when running)
1.5.6  Added additional check to discovery report -- check for any files that are present in the bundle directory but not referenced in the manifest
1.5.7  Add the ability to check the uniqueness of source IDs to the discovery report
1.5.8  bug fixes, update to fix tests
1.5.9  update generate_collection_report to add more columns
1.6.0  rename generate_collection_report to project_tag_report and add a new report that uses the progress YAML file to only report on successfully accessioned druids
1.6.1  allow users to specify a manifest file for descriptive metadata purposes even if should_register=false; allow users to bypass image validation
1.7.0  allow for 'joined' method of content metadata generation; allow user to specify publish/preserve/shelve attributes by mime-type
1.7.1  add further validation checks to ensure only compatible values are set in YAML before proceeding, some refactoring to keep bundle class smaller, remove 'use_druid_minter' parameter 
and set it to a new style of getting druids, show warnings if you set development only parameters
1.7.2  set completion_report to check actual workflow states in DOR instead of relying on SOLR, which can be out of date
1.7.3  small bug fix when checking writable status of directories and files; try and find druids from barcodes when running discovery report
1.7.4  more validation fixes, to indicate that container barcode projects must have the APO DRUID set
1.7.5  add another check to discovery_report which confirms readable file permissions on object files
1.7.6  bug fix in discovery_report for barcode projects
1.7.7  move the Utils class into it's own gem so it can be used elsewhere ... methods that were PreAssembly::Utils are now Assembly::Utils; refactoring to account for new DruidTools gem usage
1.7.8  bug fixes; update how configuration is done to make it part of Assembly-utils gem
1.7.9  add time stamps to progress display on screen (or into nohup.out file)
1.8.0  allow the web service call to retry 5 times, sleeping between each call in order to avoid pre-assembly crashing if the dor web service is temporarily unavailable
1.8.1  refactor: adjust object_file class to subclass from Assembly::ObjectFile so we don't need to redeclare convenience methods
1.9.0  use the content metadata generation methods in the updated Assembly::ObjectFile gem, which expands the possible types of metadata that can be generated, update templates and documentation
1.9.1  use the new DruidTools gem to generate staged content in the druid tree format: /oo/000/oo/0001/oo000oo0001/content
1.9.2  update how set relationships are stored in an object -- add both an isMemberOf and an isMemberOfRelationship
1.9.3  small updates to force new usage of assembly-objectfile gem for latest contentmetadata generation; additional output at end of preassembly
1.9.4  update discovery_report to include checks for APO existence and existence of assemblyWF workflow definition
1.9.5  more additions to discovery_report to provide total size and count by mimetype of discovered files; eliminate need to directly compute md5; this is now done via the assembly-objectfile gem
1.9.6  add a new configuration parameter that determines if items are staged using the new style of druid trees or the old style of druid trees in the dor workspace
1.9.7  provide the option to have no contentMetadata.xml file generated during pre-assembly.  Useful if you have a current custom created one ready to stage.
1.9.8  update web service call to remove "v1" from URL
1.9.9  allow the content metadata creation style to be discovered from already registered objects by inspecting the 'Process : Content Type' tag.  The default is used if not found or mapping incomplete.
1.10.0 added support for the dir_validator gem
1.10.1 updated discovery report to fetch druids; add files needed for mjf
1.10.2 update discovery report to optionally show all staged files; add new parameter to stageable discovery to optionally stage files only
1.10.3 show detailed exception messages if initiate_accessioning_workflow step fails after several attempts (useful for debugging)
1.10.4 update discovery report
1.10.5 update README to indicate new convenience methods available in assembly-utils, update required version of assembly-utils

To check which version is running, cd into the home directory of the project and look at the VERSION file:

cd /home/lyberadmin/pre-assembly/current
more VERSION

==Project Location

The code is deployed onto sul-lyberservices-test and sul-lyberservices-prod in the /home/lyberadmin/pre-assembly with the latest version in the "current" subdirectory.

==Running

1. Gather information about your project, including:
	a. The location of the materials.  You will need read access to this location from the servers you will be accessioning in (e.g. test and production).
	b. Whether the objects are already registered or not.
	c. The location of any descriptive metadata.
	d. Whether you will be flattening the folder structure of each object when accessioning (e.g. discarding any folder structure provided to you in each object).
	e. The DRUID of the project's APO.
	f. The DRUID of the set object you will be associating your objects with (if any).
	g. If your objects are not yet registered and you have a manifest file in CSV format, make sure you have columns for sourceid, filename, and label.  See config/projects/manifest_template/TEMPLATE_manifest.csv for an example manifest.  See the "manifest" section below for more information.
	h. If you are using a manifest file in CSV format and want to create descriptive metadata, create a MODs XML template.  See the "descriptive metadata" section below for more details.
	
2. Create a project-configuration YAML file using the data you gathered above.  Store this file in a location where it can be accessed by the server (test or production).  You should create a YAML file for each environment specifying the parameters as appropriate.  Use the convention of "projectname_environment.yaml", e.g. "revs_test.yaml".  
If you have multiple collections to associate your objects with, you will need to run in multiple batches with multiple YAML files.  You can add your collection name to the end of each YAML filename to keep track (e.g. "revs_test_craig.yaml")

The YAML file can be stored anywhere that is accessible to the server you are running the code on.  However, for simplicity, we recommend you
store the YAML at the root of your bundle directory, or create a new project folder, place your YAML file into it and then place your bundle
directory into your new project folder.  PLEASE DO NOT PLACE YOUR YAML FILE INTO THE PRE-ASSEMBLY DIRECTORY ITSELF ANYWHERE ON THE SERVER.  IT WILL BECOME HARD TO FIND AND 
BE SUBJECT TO DELETION WHEN NEW CODE IS DEPLOYED.

Example:

Your content is on /thumpers/dpgthumper-staing/Hummel
Create a YAML file at /thumpers/dpgthumper-staging/Hummel/hummel_test.yaml
Move your content (if you can) into /thumpers/dpgthumper-staging/Hummel/content

If you cannot move your content, be sure your YAML bundle discovery glob and/or regex are specific enough to correctly ignore your YAML file during discovery.  Or, alternatively, place your YAML file in a location other than the bundle.

   See config/projects/TEMPLATE.yaml for a fully documented example of a configuration file.
   See config/projects/manifest_noreg_example.yaml for a specific example using a manifest.
   See config/projects/reg_example.yaml for a specific example using a file system crawl.

3. Check the permissions on the bundle directory, iteratively. You need read permissions on all the bundle directory folders and files.  You need to have write permissions in the location you
plan to write the log file too (often this cannot be the thumper drives since it is mounted as read-only).

4. You may benefit from running some objects in a local or test environment.  If your objects are already registered, this may require pre-registering a sample set in test as well as production using the same DRUIDs that are identified with your content.
You may also have to move a small batch of test content to a location that is visible to sul-lyberservices-test.  Since the thumper drives are not mounted on the test server, you can use the /dor/content mount on test for this purpose.

5. Make sure you have an APO for your object, and that the administrativeMetadata data stream has the <assemblyWF> defined in it.  If it does not, go to https://consul.stanford.edu/display/APO/Home and find the "Current FoXML APO template" link at the bottom of the page.  Download and open the template, find the <assembly> node and copy it.  Go to Fedora admin for each relevant environment (test/production) and this node to the administrativeMetadata stream.  If you don't have this workflow defined in your APO, then the assembly robots will never operate and accessioning will not operate.
This APO should be defined using the same DRUID in test and production if you intend to run in both locations.

6. You can perform a dry discovery run to test your YAML configuration.  This run will enumerate the discovered objects, 
tell you how many files were discovered in each object, check for filename uniqueness in each object, and 
confirm objects are registered with an APO (for projects where objects are pre-registered).  This dry run is particularly important if you are 
flattening each object's folder structure during pre-assembly (e.g. each object has images in a '00' and '05' directory, but you don't want to
retain those folders when accessioning), since you will want to check to make sure each file in a given object has unique filenames. 
For projects that use manifests for object discovery along with checksum files, you can optionally have checksums computed and confirmed.
This is really only useful if you are staging content and not accessioning immediately (since the accessioning process will reconfirm checksums).

First log into sul-lyberservices-test or prod as needed, and then cd into the pre-assembly directory, e.g.

	 ssh lyberadmin@sul-lyberadmin-test.stanford.edu
	 cd pre-assembly/current
   ROBOT_ENVIRONMENT=test bin/discovery_report YAML_FILE

You will probably want to run this against a specific environment so it can connect to DOR and confirm registration on the appropriate server, e.g:

	ROBOT_ENVIRONMENT=production bin/discovery_report YAML_FILE
	
You will see a report containing :
a) the total number of objects discovered
b) the names of each discovered object along with the number of files which will be discovered in that object
c) any entries (directories or files) in the bundle directory which will *not* be discovered based on your configuration.
d) the total number and listing of any objects which have duplicate filenames.  You must resolve the duplicate filenames if you intend to flatten the folder structure when accessioning.
e) for manifest style projects, the label and source id along with if all source IDs contained in the manifest are unique 
g) for manifest style projects, a listing of any folders/files present in the bundle directory that are not referenced in the manifest...
some will be expected (such as a checksum file), but this will let you see if any expected images/data are missing from the manifest

If any errors occur, they will be displayed and a total error count is shown at the bottom.

To send the report to a CSV file for better sorting and viewing in Excel, send the output to a file using normal UNIX syntax, e.g.:

	ROBOT_ENVIRONMENT=production bin/discovery_report YAML_FILE > /full/path/to/report/filename.csv

When sending output to a CSV, you will not see any terminal output while the report is running.

Options for discovery report:

You can add the following parameters after the YAML_FILE name.  Note that adding each option may make the report time consuming, especially
for large number of objects.  Some options only work for certain styles of projects.

confirm_checksums   =  for manifest style projects, will compute and confirm checksums against the checksum file if it exists -- useful it you are not accessioning immediately
check_sourceids  =  for manifest style projects, will confirm source IDs are globally unique in DOR (sources ids area already checked for local uniqueness in the manifest)
no_check_reg = for projects where objects are to be registered, DONT'T check if objects are registered and have APOs (assuming they are supposed to be registered already)
show_staged = will show all files that will be staged (warning: will produce a lot of output if you have lots of objects with lots of files!)

e.g.

ROBOT_ENVIRONMENT=production bin/discovery_report YAML_FILE confirm_checksums check_sourceids > report.csv


7. To run pre-assembly locally:

    # Normal run.  Will restart and crete a new log file, overwriting any existing log file for that project.
    bin/pre-assemble YAML_FILE

    # Run in resume mode, which will automatically pick up where left off based on the log file.
    bin/pre-assemble YAML_FILE --resume

Again, you can add ROBOT_ENVIRONMENT=XXXX to the beginning of the command to run in test, production or other modes as needed.

8. Running in the production environment:

    - Navigate to the production box, in the pre-assembly area.
    - Set the ROBOT_ENVIRONMENT to production.
    - Run pre-assembly with nohup and in the background (&).
    - Optionally, include the --resume option.
	
	See the example below:

    ssh lyberadmin@sul-lyberservices-prod.stanford.edu
    cd /home/lyberadmin/pre-assembly/current
    ROBOT_ENVIRONMENT=production nohup bin/pre-assemble YAML_FILE &

	If you want to run multiple nohup jobs simultaneously, you can redirect screen output to a different log file:
	
		ROBOT_ENVIRONMENT=production nohup bin/pre-assemble YAML_FILE > another_nohup_filename.out 2>&1&
	
    # Various ways to monitor progress:
    1. The workflow grid in Argo, using your project tag to filter.
    2. grep pid PROGRESS_LOG          # Using the filename defined in YAML progress_log_file.
    3. tail -999f log/production.log  # Detailed logging info for the pre-assembly project itself.
    4. tail -999f nohup.out           # Errors, etc from unix output (or "another_nohup_filename.out" in the example above)

Be sure to keep your progress log file somewhere useful and be aware if you restart pre-assembly without using the --resume switch, it will be overwritten.
You will need the progress log for cleanup and restarting.

==Legacy Project Notes

The assembly robots will automatically create jp2 derivates from any TIFFs, JP2s, or JPEGs.  If you are working on a legacy project that has JP2s already that 
were generated from source TIFFs, you should *not* stage those files during pre-assembly, or else you will end up with two JP2s for each TIFF.
You can do this by using a regex to exclude .JP2 files or by only staging certain subfolders.  If you do stage the JP2 files and they have the same
filename as the TIFF (but with a different extension) they will be kept as is (i.e. they will NOT have JP2s re-generated from the source TIFFs).  If you do stage the
JP2 files and they have a different basename than the TIFFs, they WILL be re-generated, and you will end up with two copies, in two different resources.

==Environments

Use the ROBOT_ENVIRONMENT=xxxxx in front of commands to run in a specific environment.  Current available environments are:

* local  - your laptop
* development - development servers
* test - test servers
* production - production servers

The server environments define which instance of DOR is connected to, as well as the workflow and other services.  If you run in the incorrect
environment, you will find your objects registered in unexpected places, or you may run into errors when objects you believe should be registered
are not.

==Screen Command

If screen is installed on the server you are using (currently not in production), another possibility instead of running nohup is to run 
using the "screen" command.  (NOTE: currently, screen is not available in production).

Start a new screen by typing:

$  screen

You can then start pre-assembly without nohup, just like you would locally:

$  ROBOT_ENVIRONMENT=production bin/pre-assemble YAML_FILE

You can then detach from the screen by pressing ctrl-a, ctrl-d and then exit from the server.

You can come back to your screen by re-logging into the server, and typing 

$ screen -r

You can also see a list of available screens by typing

$ screen -list

For more info on screen, see http://kb.iu.edu/data/acuy.html


==Troubleshooting

1. If you don't see all of your objects being discovered or no files are found in discovered objects, check the permissions on the bundle directory.
You need read permissions on all the bundle directory folders and files.

2. Be sure you are running on the correct server in the correct environment.  See the "environment" section above.

3. Be sure you have read access to the YAML file you created from the server you are running on.

4. Be sure you have write access to the location you have specified for your progress log file.  When running as lyberadmin on the test and production
machines, you will NOT have write access to the thumper drivers.  You should store your progress log file elsewhere, such as /dor/preassembly

5. Check to see if the assembly and accessioning robots are running in the environment you are using.  See the "Starting Robots" section below.
It is not recommended that you start robots in production without consulting the Lyberstructure team.

6. If you don't see JP2s being created (or recreated) for your content, this is probably due to one of the following problems:

a. The content metadata generated by pre-assembly didn't set a resource type or set a resource type other than "image" or "page".  Assembly
will only create jp2s for images containing in resources marked as "image" or "page".  Pre-assembly will do this automatically for
:simple_image and :simple_book projects, but check the output of the content metadata to be sure.

b. The image was not a mimetype of 'image/jpeg' or 'image/tiff'.  Any other mimetype will be ignored.

c. Your input image was corrupt or missing a color space profile.  This will usually cause the jp2-create robot to fail and throw an error in that workflow step.

d. You had an existing JP2 in the directory that matched a tiff or jpeg.  In this case the jp2-create robot will not overwrite any existing files just to be safe.
 
7. If you see incorrect content metadata being generated, note that if should_register = false, the 'Process : Content Type' tag for each existing
object will be examined.  If a known type is set in this tag, it will be used to create content metadata instead of the default set in
project_style[:content_structure].  Check the tag for each object if the style is not matching what you have set in the YAML configuration file.
Also note that if content_md_creation[:style] is set to 'none', then no content metadata will be generated.

==Restarting a job

If you have failed objects during your pre-assembly, these will either cause pre-assembly to terminate immediately (if the failure is non-recoverable)
or it will continue and log the errors.  The progress log file you specified in your YAML configuration will contain information about which bundles failed.
You can re-start pre-assembly and ask it to re-try the failed objects and continue with any other objects that it hadn't done yet.  To do this,
use the --resume flag when you run pre-assembly:

    ROBOT_ENVIRONMENT=production bin/pre-assemble YAML_FILE --resume

==Post Accessioning Reports

Two reports are available.  Both produce the following output, but differ in how they locate objects to report on.  The output for both reports
is a CSV file in the "log" folder of your checked out pre-assembly code.  Both will report on up to 50,000 rows and includes the following columns:

* druid
* label
* source_id
* dc:title
* published status
* shelved status
* PURL url 
* total files in object
* number of files by file extension

The first report is called a "project_tag_report" and includes ALL objects in DOR tagged with a specific project tag.  This is useful for a global project overview and
is cumulative (i.e. as more objects are added with that tag, the report will be bigger if run again).

ROBOT_ENVIRONMENT=production bin/project_tag_report PROJECT_TAG

where PROJECT_TAG is the Argo project tag (e.g. "Revs").  If your project tag has spaces in it, be sure to use quotes, like this:

ROBOT_ENVIRONMENT=production bin/generate_collection_report "Stanford Oral History Project"

The second report is called a "completion_report" and uses the pre-assembly YAML configuration file to determine the successfully accessioned objects.  Only those objects are included
in the report.  The report is run with:

ROBOT_ENVIRONMENT=production bin/completion_report YAML_FILE

e.g.:

ROBOT_ENVIRONMENT=production bin/completion_report /thumpers/dpgthumper2-smpl/SC1017_SOHP/sohp_prod_accession.yaml


==Manifests

Manifests are a way of indicating which objects you will be accessioning.  A manifest file is a CSV, UTF-8 encoded file and works for projects
which have one file per object (container = one file in this case), or projects with many files per object (container = folder in this case).  

There are a few columns required in the manifest depending on if should_register is true or false:

container = container name (either filename or folder name) -- always required
sourceid  = source ID used when registering (required if should_register = true)
label     = label used when registering (required if should_register = true)
druid     = druid of object (required if should_register = false, used to identify which object the row refers to)

The first line of the manifest is a header and specifies the column names. Column names should not have spaces and it is easiest if they are all lower case. 
These columns are used to register objects and indicate which file goes with the object.  If the container column specifies a filename, it should be relative to the manifest file itself.  
You can have additional columns in your manifest which can be used to create descriptive metadata for each object.  See the section below for more details on how this works.

The actual names of the columns above (except for "druid") can be set in the YAML file.

A sample manifest file is located in config/projects/manifest_template/TEMPLATE_manifest.csv for an example.  

==Descriptive Metadata

If descriptive metadata is supplied in a source known to common accessioning (currently MDToolkit or Symphony), then no action is required during pre-assembly other than ensuring your DRUIDs and/or barcodes match the ones in MDToolkit or Symphony.

If you are supplying a manifest file instead of using object discovery via file system crawling, then you can also create a descriptive metadata MODs file for each object using content supplied in the manifest.  By creating a template XML MODS file, placing with your YAML configuration file and ensuring it's filename is indicated in your YAML configuration, you can tell pre-assembly to generate a MODs file per object.  The generated MODs file will be called "descriptiveMetadata.xml" and will be staged alongside the content.  This file is automatically picked up during common accessioning.  

The MODs file is generated by taking the XML template you supply, and filling in any [[FIELD]] values in the template with the corresponding column from the manifest.

For example, if your template has

<mods><title>[[description]]</title></mods>

and you have a column called "description" in your manifest and you have a row with a value of "picture of me", you will get that value filled into your template for that specific object:

<mods><title>picture of me</title></mods>

In addition, the entire MODs template is passed through an ERB parser, allowing you to utilize Ruby code in the template using the standard <% %> syntax.  This can be used to peform more complex operations.  If you utilize Ruby code, you will have access to a special local variable called 'manifest_row', which is a hash of values for that row in the manifes, keyed off the column names.  For example:

 <mods><title><%= manifest_row[:description] %></title></mods>
 
will provide the same output as the previous example.  A full example of a MODs template is provided at config/projects/manifest_template/TEMPLATE_mods.xml

== Accession of Specific Objects

For projects with a manifest (e.g. like Revs):

1. Create a new manifest with only the objects you need accessioned.
2. Create a new project config YAML file referencing the new manifest and write to a new progress log file.
3. Run pre-assembly.

For projects that do not use a manifest and which have their objects already registered (e.g. like Rumsey):

1. Create a new project config YAML file and set the parameter 'accession_items' using either the 'only' or 'except' parameter as needed.
You can include only specific objects (useful when you only want to run a few objects) or you can exclude specific objects (useful when you want
to run most).  Set the 'reaccession' parameter to false or nil.  Also set a different progress log file so
you can store the results of your second run separately.  See the TEMPLATE.yaml for some examples.
2.  Run pre-assembly.

== Re-Accession of Specific Objects

Very similar to above, if you need to re-accession a batch of material (for example, after remediating some files in your bundle), you can do this in two ways,
depending on your project setup.

For projects with a manifest (e.g. like Revs):

1. Create a new manifest with only the objects you need re-accessioned.
2. Create a new project config YAML file referencing the new manifest and write to a new progress log file.
3. "Cleanup" your existing objects that you will be re-accessioning using the "Assembly::Utils.cleanup" method on a Ruby console as described below.
Since you will be re-registering objects, you will get new DRUIDs, and you should therefore be sure to completely delete your old objects.
4.  Re-run pre-assembly.

For projects that do not use a manifest and which have their objects already registered (e.g. like Rumsey):

1. Create a new project config YAML file and set the parameter 'accession_items' and the 'only' parameter to an array of bundle names
(e.g. druid folder names) that you want to re-accession.  Set the 'reaccession' parameter to true.  Also set a different progress log file so
you can store the results of your second run separately.  See the TEMPLATE.yaml for some examples.
2.  Re-run pre-assembly.

This process will perform an automatic cleanup on the items being re-accessioned (but will leave your objects registered).

==Cleanup

=== Removing Items From DOR and other locations

If you need to cleanup accessioned content, you can do this in two ways.  The first will use the YAML configuration file and the
associated progress log file to indicate which objects you would like removed.  Note that the YAML configuration file specifies the 
location of the progress log file.  If the progress log file has been moved or changed, this will not work correctly.  You should
confirm that your YAML configuration file still correctly specifies the location of "progress_log_file". The script will open the YAML configuration, find the progress log,
read it to find the actual completed objects, and will then execute cleanup on those objects.  Use the following script to perform a cleanup:

		ROBOT_ENVIRONMENT=xxx bin/cleanup YAML_PROGRESS_LOG_FILE steps
		
where steps is a comma delimited list of any or all of the following steps defined below:

symlinks == remove symlinks from the /dor/workspace
stage    == removed staged files (typically stored in /dor/assembly, but the specific area is defined as 'staging_dir' in the YAML file)
dor      == remove objects from Fedora
stacks   == remove files from the stacks that were shelved during accessioning ... note this step must be run from a server
(such as sul-lyberservices-test) and you must be able to authenticate to the relevant stacks server

You can also specify the environment using ROBOT_ENVIRONMENT, just as with a pre-assembly run.  Since this script is destructive, you will need
to confirm each step.  It is always best to run this script on the test (or production) server, since then it will have full access to the stacks.

For example, when on sul-lyberservices-test:

		ROBOT_ENVIRONMENT=test bin/cleanup tmp/revs.yaml symlinks,stage,dor

The second way to perform a cleanup is from a bin/console prompt running the appropriate environment.  You can then specify a specific
list of druids and steps (as an array of symbols) to cleanup:

e.g. 

$ ROBOT_ENVIRONMENT=test bin/console

druids=%w{druid:aa111aa1111 druid:bb222bb2222}
steps=[:symlinks,:stage,:dor,:stacks]
Assembly::Utils.cleanup(:druids=>druids,:steps=>steps,:dry_run=>true)

=== Loading YAML Configuration

If you are working in the console, and want to read your YAML configuration file (for example, to determine where your progress log file is located), you can
use the following methods to load the configuration into a ruby hash:

e.g. 

$ ROBOT_ENVIRONMENT=test bin/console

config_filename='/thumpers/dpgthumper2-smpl/SC1017_SOHP/sohp_prod_accession.yaml'
config=Assembly::Utils.load_config(config_filename)
progress_filename=config['progress_log_file']

You can then use these values in other utility methods as needed.

=== Finding Druids 

If you want to find the druids from your progress log file that are either completed or not completed, you can use a method that will give you
an array of relevant druids.  You can then use this array in 'workflow_status' method noted above or in the other utility methods.

e.g. 

$ ROBOT_ENVIRONMENT=test bin/console

completed_druids=Assembly::Utils.get_druids_from_log('/dor/preassembly/sohp_accession_log.yaml',true)
failed_druids=Assembly::Utils.get_druids_from_log('/dor/preassembly/sohp_accession_log.yaml',false)

# e.g. get workflow status of failed druids:
Assembly::Utils.workflow_status(:druids=>failed_druids,:workflows=>[:assembly,:accession],:filename=>'output.csv')

If you want to find druids by source_id, use the utility method Assembly::Utils.get_druids_by_sourceid(source_ids=[]) to do this.  You can then
use the array of druids in the other utility methods.

e.g. 

$ ROBOT_ENVIRONMENT=test bin/console

source_ids=%w{foo:123 bar:456}
druids=Assembly::Utils.get_druids_by_sourceid(source_ids)
Assembly::Utils.workflow_status(:druids=>druids,:workflows=>[:assembly,:accession],:filename=>'output.csv')

=== Workflow Status Report

If you want to check on the status of objects in DOR without using Argo, you can do this using the following method.  You can specify
assembly and/or accession workflows (as symbols), and also a filename if you want the report written to disk in CSV format.

$ ROBOT_ENVIRONMENT=test bin/console

druids=%w{druid:aa111aa1111 druid:bb222bb2222}
Assembly::Utils.workflow_status(:druids=>druids,:workflows=>[:assembly,:accession])  # add :filename=>'output.csv' to get a CSV report

=== Updating Datastreams

Once you have content accessioned, you might need to batch update datastreams (for example, to globally fix a typo).  You can do this by providing an
array of druids, the name of a datastream and some new content:

druids=%w{druid:aa111aa1111 druid:bb222bb2222}
new_content='<xml><more nodes>this should be the whole datastream</more nodes></xml>'
datastream='rightsMetadata'
Assembly::Utils.replace_datastreams(druids,datastream,new_content)

You can also just replace a part of a datastream instead of the whole thing.  Be careful, this just runs a .gsub on the entire datastream, so it can do damage
if you aren't careful.

druids=%w{druid:aa111aa1111 druid:bb222bb2222}
find_content='FooBarBaz'
replace_content='Stanford Rules'
datastream='rightsMetadata'
Assembly::Utils.update_datastreams(druids,datastream,find_content,replace_content)

A helper method is provided to update rightsMetadata using the default rights contained in an APO.  To do this, supply a list of druids to update and
the druid of the APO to get default rights from:

druids=%w{druid:aa111aa1111 druid:bb222bb2222}
apo_druid='druid:cc222cc2222'
Assembly::Utils.update_rights_metadata(druids,apo_druid)

=== Finding Errored Out Objects

You can get a hash containing objects that have errored out in a specific workflow and step, including the error message.  Note that if you
don't supply a tag, both of the following commands work for *ALL* objects in DOR, they are not specific to your project.
If you do supply a tag, it should be exact (e.g. 'Project : Revs'), and if you have a lot of objects in DOR in a specific error state, the call
may take a long time, since it will need to look up each object in DOR.

$ ROBOT_ENVIRONMENT=test bin/console

result=Assembly::Utils.get_errored_objects_for_workstep('accessionWF','content-metadata')

To filter to a specific project, supply a tag:

result=Assembly::Utils.get_errored_objects_for_workstep('accessionWF','content-metadata','Project : Revs')

You can also automatically reset all of those objects to waiting:

result=Assembly::Utils.reset_errored_objects_for_workstep('accessionWF','content-metadata')

You can also supply a tag here:

result=Assembly::Utils.reset_errored_objects_for_workstep('accessionWF','content-metadata','Project : Revs')


=== Reset Workflow States

If an object fails for some reason and you manually remediate something, you may need to reset the workflow state for certain steps to try again.
You can reset any workflow steps back to "waiting" for any list of druids you specify and any workflow states.  
To do this use the Assembly::Utils.reset_workflow_states method.
Provide a list of druids in an array, and a hash containing workflow names (e.g. 'assemblyWF' or 'accessionWF') as the keys, and arrays of steps
as the corresponding values (e.g. ['checksum-compute','jp2-create']) and they will all be reset to "waiting".

e.g. 

$ ROBOT_ENVIRONMENT=test bin/console

druids=%w{druid:aa111aa1111 druid:bb222bb2222}
steps={'assemblyWF'  => ['checksum-compute'],'accessionWF' => ['content-metadata','descriptive-metadata']}
Assembly::Utils.reset_workflow_states(:druids=>druids,:steps=>steps)

==Starting Robots

If you are on the test or production server, you can determine if the robots are running and you can print out the command to start them.

$ ROBOT_ENVIRONMENT=test bin/console

Assembly::Utils.robot_status # check to see if the assembly and accession robots are running and print out status report

If the robots are not running, you can see how to start them.  It won't execute the commands, you can do that yourself at a unix prompt.

Assembly::Utils.start_robots 


==Assembly Robots

The last step of pre-assembly is the initiation of the assembly workflow for a given object.  This assumes the assemblyWF is defined in the APO referenced by the project, and it also assumes the assembly robots are running on the server.  If the assembly robots are not running, then JP2 creation and all follow up steps will not occur.  You can determine if the robots are running on the server with:

ps -ef | grep assemblyWF

If you see only one line, something like below, the assembly robots are  NOT running:
501 26382 26097   0  1:04PM ttys001    0:00.00 grep assemblyWF

If you see multiple lines, something like below, the assembly robots are running:
503        782     1  0 10:25 ?        00:00:04 assemblyWF:jp2-create
503        784     1  0 10:25 ?        00:00:04 assemblyWF:checksum-compute
503        789     1  0 10:25 ?        00:00:07 assemblyWF:exif-collect
503        791     1  0 10:25 ?        00:00:10 assemblyWF:accessioning-initiate
503       9009  8909  0 13:05 pts/0    00:00:00 grep assemblyWF

To start the assembly robots, use the following line.  If you are in production substitute "production" for "test" in the robot_environment variable:
	cd /home/lyberadmin/assembly/current; ROBOT_ENVIRONMENT=test ./bin/run_robot start assemblyWF:jp2-create assemblyWF:checksum-compute assemblyWF:exif-collect assemblyWF:accessioning-initiate

You can track the progress of each assembly robot by inspecting it's log file on the server.  To see the available log files (one for each robot):
	ls /home/lyberadmin/assembly/current/log
	
Tail a file to watch it's output, e.g.
	tail -f /home/lyberadmin/assembly/current/log/jp2-create.log

Or inspect it for a more complete history, e.g.
	less /home/lyberadmin/assembly/current/log/jp2-create.log

More information on the assembly robots is found in the assembly project here:

corn.stanford.edu:/afs/ir/dev/dlss/git/lyberteam/assembly.git

==Deployment

See Capfile.

==Setting up code for local development

    # Clone project.
    git clone `whoami`@corn.stanford.edu:/afs/ir/dev/dlss/git/lyberteam/pre-assembly.git
    cd pre-assembly

    # Set up some stuff not stored in Git.
    mkdir doc log pkg tmp
    RCONF='lyberadmin@lyberservices-dev.stanford.edu:/home/lyberadmin/pre-assembly/config'
    scp -r $RCONF/certs $RCONF/environments config

    # Get needed gems.
    bundle install

    # Confirm that it's working.  Note that for integration tests to work, you will need to be on the Stanford network and kerberos         # authenticated
    bin/run_all_tests 


==Running tests

For local testing, it's easiest to put this in your bash profile:

	export ROBOT_ENVIRONMENT=local

Running tests:

    # All tests.  Note that to run integration tests you will need to be on the Stanford network since they will attempt to access DOR-dev
    bin/run_all_tests

    # Unit tests and integration tests separately.
    bundle exec rspec spec
    bundle exec rspec integration
